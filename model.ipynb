{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.layers import Lambda, Cropping2D, Conv2D, MaxPooling2D, Dropout, Dense, Flatten,BatchNormalization\n",
    "import os\n",
    "import csv\n",
    "import matplotlib.image as mpimg\n",
    "import easydict\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Exploration & Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = './data'\n",
    "data = pd.read_csv(os.path.join(data_dir,'driving_log.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>/Users/kibaekjeong/Desktop/cloning data/IMG/center_2019_09_06_17_43_40_849.jpg</th>\n",
       "      <th>/Users/kibaekjeong/Desktop/cloning data/IMG/left_2019_09_06_17_43_40_849.jpg</th>\n",
       "      <th>/Users/kibaekjeong/Desktop/cloning data/IMG/right_2019_09_06_17_43_40_849.jpg</th>\n",
       "      <th>0</th>\n",
       "      <th>0.1</th>\n",
       "      <th>0.2</th>\n",
       "      <th>7.420227E-06</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/Users/kibaekjeong/Desktop/cloning data/IMG/ce...</td>\n",
       "      <td>/Users/kibaekjeong/Desktop/cloning data/IMG/le...</td>\n",
       "      <td>/Users/kibaekjeong/Desktop/cloning data/IMG/ri...</td>\n",
       "      <td>-0.013971</td>\n",
       "      <td>0.034260</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/Users/kibaekjeong/Desktop/cloning data/IMG/ce...</td>\n",
       "      <td>/Users/kibaekjeong/Desktop/cloning data/IMG/le...</td>\n",
       "      <td>/Users/kibaekjeong/Desktop/cloning data/IMG/ri...</td>\n",
       "      <td>-0.028493</td>\n",
       "      <td>0.283845</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.139888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/Users/kibaekjeong/Desktop/cloning data/IMG/ce...</td>\n",
       "      <td>/Users/kibaekjeong/Desktop/cloning data/IMG/le...</td>\n",
       "      <td>/Users/kibaekjeong/Desktop/cloning data/IMG/ri...</td>\n",
       "      <td>-0.033318</td>\n",
       "      <td>0.481680</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.465651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/Users/kibaekjeong/Desktop/cloning data/IMG/ce...</td>\n",
       "      <td>/Users/kibaekjeong/Desktop/cloning data/IMG/le...</td>\n",
       "      <td>/Users/kibaekjeong/Desktop/cloning data/IMG/ri...</td>\n",
       "      <td>-0.034926</td>\n",
       "      <td>0.692577</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.022985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/Users/kibaekjeong/Desktop/cloning data/IMG/ce...</td>\n",
       "      <td>/Users/kibaekjeong/Desktop/cloning data/IMG/le...</td>\n",
       "      <td>/Users/kibaekjeong/Desktop/cloning data/IMG/ri...</td>\n",
       "      <td>-0.038695</td>\n",
       "      <td>0.881505</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.648629</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  /Users/kibaekjeong/Desktop/cloning data/IMG/center_2019_09_06_17_43_40_849.jpg  \\\n",
       "0  /Users/kibaekjeong/Desktop/cloning data/IMG/ce...                               \n",
       "1  /Users/kibaekjeong/Desktop/cloning data/IMG/ce...                               \n",
       "2  /Users/kibaekjeong/Desktop/cloning data/IMG/ce...                               \n",
       "3  /Users/kibaekjeong/Desktop/cloning data/IMG/ce...                               \n",
       "4  /Users/kibaekjeong/Desktop/cloning data/IMG/ce...                               \n",
       "\n",
       "  /Users/kibaekjeong/Desktop/cloning data/IMG/left_2019_09_06_17_43_40_849.jpg  \\\n",
       "0  /Users/kibaekjeong/Desktop/cloning data/IMG/le...                             \n",
       "1  /Users/kibaekjeong/Desktop/cloning data/IMG/le...                             \n",
       "2  /Users/kibaekjeong/Desktop/cloning data/IMG/le...                             \n",
       "3  /Users/kibaekjeong/Desktop/cloning data/IMG/le...                             \n",
       "4  /Users/kibaekjeong/Desktop/cloning data/IMG/le...                             \n",
       "\n",
       "  /Users/kibaekjeong/Desktop/cloning data/IMG/right_2019_09_06_17_43_40_849.jpg  \\\n",
       "0  /Users/kibaekjeong/Desktop/cloning data/IMG/ri...                              \n",
       "1  /Users/kibaekjeong/Desktop/cloning data/IMG/ri...                              \n",
       "2  /Users/kibaekjeong/Desktop/cloning data/IMG/ri...                              \n",
       "3  /Users/kibaekjeong/Desktop/cloning data/IMG/ri...                              \n",
       "4  /Users/kibaekjeong/Desktop/cloning data/IMG/ri...                              \n",
       "\n",
       "          0       0.1  0.2  7.420227E-06  \n",
       "0 -0.013971  0.034260  0.0      0.001163  \n",
       "1 -0.028493  0.283845  0.0      0.139888  \n",
       "2 -0.033318  0.481680  0.0      0.465651  \n",
       "3 -0.034926  0.692577  0.0      1.022985  \n",
       "4 -0.038695  0.881505  0.0      1.648629  "
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "row = ['center','left','right','steering','throttle','brake','speed']\n",
    "with open('./data/clean_data.csv','w') as csvFile:\n",
    "    writer = csv.writer(csvFile)\n",
    "    writer.writerow(row)\n",
    "    for i in range(len(data)):\n",
    "        row = [data['/Users/kibaekjeong/Desktop/cloning data/IMG/center_2019_09_06_17_43_40_849.jpg'][i][40:],data['/Users/kibaekjeong/Desktop/cloning data/IMG/left_2019_09_06_17_43_40_849.jpg'][i][40:],data['/Users/kibaekjeong/Desktop/cloning data/IMG/right_2019_09_06_17_43_40_849.jpg'][i][40:],data['0'][i],data['0.1'][i],data['0.2'][i],data['7.420227E-06'][i]]\n",
    "        writer.writerow(row)\n",
    "csvFile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_data = pd.read_csv(os.path.join(data_dir,'clean_data.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>center</th>\n",
       "      <th>left</th>\n",
       "      <th>right</th>\n",
       "      <th>steering</th>\n",
       "      <th>throttle</th>\n",
       "      <th>brake</th>\n",
       "      <th>speed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>IMG/center_2019_09_06_17_43_40_926.jpg</td>\n",
       "      <td>IMG/left_2019_09_06_17_43_40_926.jpg</td>\n",
       "      <td>IMG/right_2019_09_06_17_43_40_926.jpg</td>\n",
       "      <td>-0.013971</td>\n",
       "      <td>0.034260</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>IMG/center_2019_09_06_17_43_40_994.jpg</td>\n",
       "      <td>IMG/left_2019_09_06_17_43_40_994.jpg</td>\n",
       "      <td>IMG/right_2019_09_06_17_43_40_994.jpg</td>\n",
       "      <td>-0.028493</td>\n",
       "      <td>0.283845</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.139888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>IMG/center_2019_09_06_17_43_41_064.jpg</td>\n",
       "      <td>IMG/left_2019_09_06_17_43_41_064.jpg</td>\n",
       "      <td>IMG/right_2019_09_06_17_43_41_064.jpg</td>\n",
       "      <td>-0.033318</td>\n",
       "      <td>0.481680</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.465651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>IMG/center_2019_09_06_17_43_41_142.jpg</td>\n",
       "      <td>IMG/left_2019_09_06_17_43_41_142.jpg</td>\n",
       "      <td>IMG/right_2019_09_06_17_43_41_142.jpg</td>\n",
       "      <td>-0.034926</td>\n",
       "      <td>0.692577</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.022985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>IMG/center_2019_09_06_17_43_41_209.jpg</td>\n",
       "      <td>IMG/left_2019_09_06_17_43_41_209.jpg</td>\n",
       "      <td>IMG/right_2019_09_06_17_43_41_209.jpg</td>\n",
       "      <td>-0.038695</td>\n",
       "      <td>0.881505</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.648629</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   center  \\\n",
       "0  IMG/center_2019_09_06_17_43_40_926.jpg   \n",
       "1  IMG/center_2019_09_06_17_43_40_994.jpg   \n",
       "2  IMG/center_2019_09_06_17_43_41_064.jpg   \n",
       "3  IMG/center_2019_09_06_17_43_41_142.jpg   \n",
       "4  IMG/center_2019_09_06_17_43_41_209.jpg   \n",
       "\n",
       "                                   left  \\\n",
       "0  IMG/left_2019_09_06_17_43_40_926.jpg   \n",
       "1  IMG/left_2019_09_06_17_43_40_994.jpg   \n",
       "2  IMG/left_2019_09_06_17_43_41_064.jpg   \n",
       "3  IMG/left_2019_09_06_17_43_41_142.jpg   \n",
       "4  IMG/left_2019_09_06_17_43_41_209.jpg   \n",
       "\n",
       "                                   right  steering  throttle  brake     speed  \n",
       "0  IMG/right_2019_09_06_17_43_40_926.jpg -0.013971  0.034260    0.0  0.001163  \n",
       "1  IMG/right_2019_09_06_17_43_40_994.jpg -0.028493  0.283845    0.0  0.139888  \n",
       "2  IMG/right_2019_09_06_17_43_41_064.jpg -0.033318  0.481680    0.0  0.465651  \n",
       "3  IMG/right_2019_09_06_17_43_41_142.jpg -0.034926  0.692577    0.0  1.022985  \n",
       "4  IMG/right_2019_09_06_17_43_41_209.jpg -0.038695  0.881505    0.0  1.648629  "
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48197"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(clean_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model for Behavioral cloning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "class generator():\n",
    "    def load(data_dir,img_path):\n",
    "        return mpimg.imread(data_dir+img_path)\n",
    "    def rgb2yuv(img):\n",
    "        # Transform RGB to YUV color space.\n",
    "        return cv2.cvtColor(img,cv2.COLOR_RGB2YUV)\n",
    "    def random_choose(data_dir,center,left,right,steering):\n",
    "        rand = np.random.choice(3)\n",
    "        if rand == 0:\n",
    "            return generator.load(data_dir,center),steering\n",
    "        elif rand == 1:\n",
    "            return generator.load(data_dir,left),(steering + 0.2) #correction for left image\n",
    "        elif rand == 2:\n",
    "            return generator.load(data_dir,right),(steering - 0.2) #correction for right image\n",
    "    \n",
    "    def flip(img,steering):\n",
    "        rand = np.random.rand()\n",
    "        #flip the image with 50% chance\n",
    "        if rand > 0.5:\n",
    "            img = cv2.flip(img,1)\n",
    "            steering *= -1\n",
    "        return img, steering\n",
    "    \n",
    "    def brightness(img):\n",
    "        rand = np.random.rand()\n",
    "        hsv = cv2.cvtColor(img,cv2.COLOR_RGB2HSV)\n",
    "        if rand > 0.2:\n",
    "            rand_bright = 0.5 + np.random.uniform()\n",
    "            hsv[:,:,2] = hsv[:,:,2]* rand_bright\n",
    "            hsv[:,:,2][hsv[:,:,2]>255]=255\n",
    "        return cv2.cvtColor(hsv,cv2.COLOR_HSV2RGB)\n",
    "    \n",
    "    def generate(data_dir,center,left,right,steering):\n",
    "        img, steering_angle= generator.random_choose(data_dir,center,left,right,steering)\n",
    "        img, steering_angle = generator.flip(img,steering_angle)\n",
    "        img = generator.brightness(img)\n",
    "        return img, steering_angle\n",
    "    \n",
    "    def batch_generator(data_dir,img_paths,steering,batch_size,training=True):\n",
    "        imgs = np.empty([batch_size,160,320,3])\n",
    "        steering_angles = np.empty(batch_size)\n",
    "        while True:\n",
    "            for i in range(batch_size):\n",
    "                index = np.random.randint(low=0,high=img_paths.shape[0])\n",
    "                center,left,right = img_paths[index]\n",
    "                steering_angle = steering[index]\n",
    "                if training == True:\n",
    "                    img, steering_angle = generator.generate(data_dir,center,left,right,steering_angle)\n",
    "                else:\n",
    "                    img = generator.load(data_dir,center)\n",
    "                imgs[i]=generator.rgb2yuv(img)\n",
    "                steering_angles[i]=steering_angle\n",
    "            yield (imgs,steering_angles)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data(param):\n",
    "    clean_data = pd.read_csv(os.path.join(param.data_dir,'clean_data.csv'))\n",
    "    X = clean_data[['center','left','right']].values\n",
    "    y = clean_data['steering'].values\n",
    "    X_train,X_valid,y_train,y_valid = train_test_split(X,y,test_size=param.test_size,random_state=param.random_state)\n",
    "    return X_train,X_valid,y_train,y_valid\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(param):\n",
    "    model = Sequential()\n",
    "    model.add(Lambda(lambda x:(x/255.0)-0.5,input_shape=(160,320,3)))\n",
    "    model.add(Cropping2D(cropping=((70,25),(0,0))))\n",
    "    model.add(Conv2D(24,(5,5),activation='elu',strides=(2,2)))\n",
    "    model.add(Conv2D(36,(5,5),activation='elu',strides=(2,2)))\n",
    "    model.add(Dropout(rate = param.drop_rate))\n",
    "    model.add(Conv2D(48,(5,5),activation='elu',strides=(2,2)))\n",
    "    model.add(Conv2D(64,(3,3),activation='elu'))\n",
    "    model.add(Dropout(rate = param.drop_rate))\n",
    "    model.add(Conv2D(64,(3,3),activation='elu'))\n",
    "    model.add(Dropout(rate = param.drop_rate))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(100,activation='elu'))\n",
    "    model.add(Dense(50,activation='elu'))\n",
    "    model.add(Dense(10,activation='elu'))\n",
    "    model.add(Dense(1))\n",
    "    model.summary()\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_train(model,param,X_train,X_valid,y_train,y_valid):\n",
    "    checkpoint = ModelCheckpoint('model-{epoch:02d}.h5',\n",
    "                                 monitor = 'val_loss',\n",
    "                                 verbose=1,\n",
    "                                 save_best_only=True,\n",
    "                                 mode='auto')\n",
    "    \n",
    "    model.compile(loss='mean_squared_error',optimizer=Adam(lr=param.lr))\n",
    "    \n",
    "    model.fit_generator(generator.batch_generator(param.data_dir,X_train,y_train,param.batch_size,True),\n",
    "                        samples_per_epoch=param.samples_per_epoch,\n",
    "                        epochs=param.epoch,\n",
    "                        validation_data = generator.batch_generator(param.data_dir,X_valid,y_valid,param.batch_size,False),\n",
    "                        verbose =1,\n",
    "                        validation_freq=1,\n",
    "                        validation_steps = param.samples_per_epoch,\n",
    "                        callbacks=[checkpoint])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    #Set parameter values\n",
    "    param = easydict.EasyDict({\n",
    "        \"data_dir\":'./data/',\n",
    "        \"drop_rate\":0.35,\n",
    "        \"epoch\":150,\n",
    "        \"batch_size\":32,\n",
    "        \"lr\":0.0001,\n",
    "        \"test_size\":0.2,\n",
    "        \"random_state\":42,\n",
    "        \"samples_per_epoch\":5000\n",
    "    })\n",
    "    \n",
    "    X_train,X_valid,y_train,y_valid = data(param)\n",
    "    driving_model = model(param)\n",
    "    model_train(driving_model,param,X_train,X_valid,y_train,y_valid)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_29\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lambda_29 (Lambda)           (None, 160, 320, 3)       0         \n",
      "_________________________________________________________________\n",
      "cropping2d_29 (Cropping2D)   (None, 65, 320, 3)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_141 (Conv2D)          (None, 31, 158, 24)       1824      \n",
      "_________________________________________________________________\n",
      "conv2d_142 (Conv2D)          (None, 14, 77, 36)        21636     \n",
      "_________________________________________________________________\n",
      "dropout_42 (Dropout)         (None, 14, 77, 36)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_143 (Conv2D)          (None, 5, 37, 48)         43248     \n",
      "_________________________________________________________________\n",
      "conv2d_144 (Conv2D)          (None, 3, 35, 64)         27712     \n",
      "_________________________________________________________________\n",
      "dropout_43 (Dropout)         (None, 3, 35, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_145 (Conv2D)          (None, 1, 33, 64)         36928     \n",
      "_________________________________________________________________\n",
      "dropout_44 (Dropout)         (None, 1, 33, 64)         0         \n",
      "_________________________________________________________________\n",
      "flatten_26 (Flatten)         (None, 2112)              0         \n",
      "_________________________________________________________________\n",
      "dense_101 (Dense)            (None, 100)               211300    \n",
      "_________________________________________________________________\n",
      "dense_102 (Dense)            (None, 50)                5050      \n",
      "_________________________________________________________________\n",
      "dense_103 (Dense)            (None, 10)                510       \n",
      "_________________________________________________________________\n",
      "dense_104 (Dense)            (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 348,219\n",
      "Trainable params: 348,219\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:17: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<generator..., epochs=200, validation_data=<generator..., verbose=1, validation_freq=1, validation_steps=5000, callbacks=[<keras.ca..., steps_per_epoch=5000)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "5000/5000 [==============================] - 1464s 293ms/step - loss: 0.0268 - val_loss: 0.0176\n",
      "\n",
      "Epoch 00001: saving model to model-01.h5\n",
      "Epoch 2/200\n",
      "5000/5000 [==============================] - 1587s 317ms/step - loss: 0.0205 - val_loss: 0.0182\n",
      "\n",
      "Epoch 00002: saving model to model-02.h5\n",
      "Epoch 3/200\n",
      "5000/5000 [==============================] - 1564s 313ms/step - loss: 0.0190 - val_loss: 0.0159\n",
      "\n",
      "Epoch 00003: saving model to model-03.h5\n",
      "Epoch 4/200\n",
      "5000/5000 [==============================] - 1526s 305ms/step - loss: 0.0177 - val_loss: 0.0160\n",
      "\n",
      "Epoch 00004: saving model to model-04.h5\n",
      "Epoch 5/200\n",
      "5000/5000 [==============================] - 1579s 316ms/step - loss: 0.0172 - val_loss: 0.0151\n",
      "\n",
      "Epoch 00005: saving model to model-05.h5\n",
      "Epoch 6/200\n",
      "5000/5000 [==============================] - 1624s 325ms/step - loss: 0.0167 - val_loss: 0.0154\n",
      "\n",
      "Epoch 00006: saving model to model-06.h5\n",
      "Epoch 7/200\n",
      "5000/5000 [==============================] - 1553s 311ms/step - loss: 0.0164 - val_loss: 0.0151\n",
      "\n",
      "Epoch 00007: saving model to model-07.h5\n",
      "Epoch 8/200\n",
      "5000/5000 [==============================] - 1595s 319ms/step - loss: 0.0160 - val_loss: 0.0150\n",
      "\n",
      "Epoch 00008: saving model to model-08.h5\n",
      "Epoch 9/200\n",
      "5000/5000 [==============================] - 1600s 320ms/step - loss: 0.0156 - val_loss: 0.0143\n",
      "\n",
      "Epoch 00009: saving model to model-09.h5\n",
      "Epoch 10/200\n",
      "5000/5000 [==============================] - 1607s 321ms/step - loss: 0.0152 - val_loss: 0.0142\n",
      "\n",
      "Epoch 00010: saving model to model-10.h5\n",
      "Epoch 11/200\n",
      "5000/5000 [==============================] - 1644s 329ms/step - loss: 0.0152 - val_loss: 0.0154\n",
      "\n",
      "Epoch 00011: saving model to model-11.h5\n",
      "Epoch 12/200\n",
      "5000/5000 [==============================] - 1562s 312ms/step - loss: 0.0147 - val_loss: 0.0160\n",
      "\n",
      "Epoch 00012: saving model to model-12.h5\n",
      "Epoch 13/200\n",
      "5000/5000 [==============================] - 1447s 289ms/step - loss: 0.0145 - val_loss: 0.0158\n",
      "\n",
      "Epoch 00013: saving model to model-13.h5\n",
      "Epoch 14/200\n",
      "5000/5000 [==============================] - 1503s 301ms/step - loss: 0.0145 - val_loss: 0.0158\n",
      "\n",
      "Epoch 00014: saving model to model-14.h5\n",
      "Epoch 15/200\n",
      "5000/5000 [==============================] - 1533s 307ms/step - loss: 0.0141 - val_loss: 0.0150\n",
      "\n",
      "Epoch 00015: saving model to model-15.h5\n",
      "Epoch 16/200\n",
      "5000/5000 [==============================] - 1538s 308ms/step - loss: 0.0141 - val_loss: 0.0151\n",
      "\n",
      "Epoch 00016: saving model to model-16.h5\n",
      "Epoch 17/200\n",
      "5000/5000 [==============================] - 1723s 345ms/step - loss: 0.0138 - val_loss: 0.0139\n",
      "\n",
      "Epoch 00017: saving model to model-17.h5\n",
      "Epoch 18/200\n",
      "5000/5000 [==============================] - 1787s 357ms/step - loss: 0.0137 - val_loss: 0.0146\n",
      "\n",
      "Epoch 00018: saving model to model-18.h5\n",
      "Epoch 19/200\n",
      "5000/5000 [==============================] - 1795s 359ms/step - loss: 0.0136 - val_loss: 0.0140\n",
      "\n",
      "Epoch 00019: saving model to model-19.h5\n",
      "Epoch 20/200\n",
      "5000/5000 [==============================] - 1799s 360ms/step - loss: 0.0133 - val_loss: 0.0136\n",
      "\n",
      "Epoch 00020: saving model to model-20.h5\n",
      "Epoch 21/200\n",
      "5000/5000 [==============================] - 1795s 359ms/step - loss: 0.0132 - val_loss: 0.0139\n",
      "\n",
      "Epoch 00021: saving model to model-21.h5\n",
      "Epoch 22/200\n",
      "5000/5000 [==============================] - 1509s 302ms/step - loss: 0.0132 - val_loss: 0.0156\n",
      "\n",
      "Epoch 00022: saving model to model-22.h5\n",
      "Epoch 23/200\n",
      "5000/5000 [==============================] - 1440s 288ms/step - loss: 0.0132 - val_loss: 0.0153\n",
      "\n",
      "Epoch 00023: saving model to model-23.h5\n",
      "Epoch 24/200\n",
      "5000/5000 [==============================] - 1420s 284ms/step - loss: 0.0132 - val_loss: 0.0152\n",
      "\n",
      "Epoch 00024: saving model to model-24.h5\n",
      "Epoch 25/200\n",
      "5000/5000 [==============================] - 1593s 319ms/step - loss: 0.0133 - val_loss: 0.0130\n",
      "\n",
      "Epoch 00025: saving model to model-25.h5\n",
      "Epoch 26/200\n",
      "5000/5000 [==============================] - 1565s 313ms/step - loss: 0.0130 - val_loss: 0.0135\n",
      "\n",
      "Epoch 00026: saving model to model-26.h5\n",
      "Epoch 27/200\n",
      "5000/5000 [==============================] - 1556s 311ms/step - loss: 0.0130 - val_loss: 0.0127\n",
      "\n",
      "Epoch 00027: saving model to model-27.h5\n",
      "Epoch 28/200\n",
      "5000/5000 [==============================] - 1551s 310ms/step - loss: 0.0127 - val_loss: 0.0127\n",
      "\n",
      "Epoch 00028: saving model to model-28.h5\n",
      "Epoch 29/200\n",
      "5000/5000 [==============================] - 1542s 308ms/step - loss: 0.0128 - val_loss: 0.0127\n",
      "\n",
      "Epoch 00029: saving model to model-29.h5\n",
      "Epoch 30/200\n",
      "5000/5000 [==============================] - 1544s 309ms/step - loss: 0.0127 - val_loss: 0.0123\n",
      "\n",
      "Epoch 00030: saving model to model-30.h5\n",
      "Epoch 31/200\n",
      "5000/5000 [==============================] - 1540s 308ms/step - loss: 0.0125 - val_loss: 0.0122\n",
      "\n",
      "Epoch 00031: saving model to model-31.h5\n",
      "Epoch 32/200\n",
      "5000/5000 [==============================] - 1535s 307ms/step - loss: 0.0124 - val_loss: 0.0127\n",
      "\n",
      "Epoch 00032: saving model to model-32.h5\n",
      "Epoch 33/200\n",
      "5000/5000 [==============================] - 1652s 330ms/step - loss: 0.0124 - val_loss: 0.0127\n",
      "\n",
      "Epoch 00033: saving model to model-33.h5\n",
      "Epoch 34/200\n",
      "5000/5000 [==============================] - 1938s 388ms/step - loss: 0.0123 - val_loss: 0.0120\n",
      "\n",
      "Epoch 00034: saving model to model-34.h5\n",
      "Epoch 35/200\n",
      "5000/5000 [==============================] - 1878s 376ms/step - loss: 0.0120 - val_loss: 0.0120\n",
      "\n",
      "Epoch 00035: saving model to model-35.h5\n",
      "Epoch 36/200\n",
      "5000/5000 [==============================] - 1871s 374ms/step - loss: 0.0121 - val_loss: 0.0121\n",
      "\n",
      "Epoch 00036: saving model to model-36.h5\n",
      "Epoch 37/200\n",
      "5000/5000 [==============================] - 1520s 304ms/step - loss: 0.0124 - val_loss: 0.0127\n",
      "\n",
      "Epoch 00037: saving model to model-37.h5\n",
      "Epoch 38/200\n",
      "5000/5000 [==============================] - 1357s 271ms/step - loss: 0.0132 - val_loss: 0.0126\n",
      "\n",
      "Epoch 00038: saving model to model-38.h5\n",
      "Epoch 39/200\n",
      "5000/5000 [==============================] - 1271s 254ms/step - loss: 0.0138 - val_loss: 0.0124\n",
      "\n",
      "Epoch 00039: saving model to model-39.h5\n",
      "Epoch 40/200\n",
      "5000/5000 [==============================] - 1264s 253ms/step - loss: 0.0139 - val_loss: 0.0120\n",
      "\n",
      "Epoch 00040: saving model to model-40.h5\n",
      "Epoch 41/200\n",
      "5000/5000 [==============================] - 1269s 254ms/step - loss: 0.0138 - val_loss: 0.0128\n",
      "\n",
      "Epoch 00041: saving model to model-41.h5\n",
      "Epoch 42/200\n",
      "5000/5000 [==============================] - 1268s 254ms/step - loss: 0.0135 - val_loss: 0.0126\n",
      "\n",
      "Epoch 00042: saving model to model-42.h5\n",
      "Epoch 43/200\n",
      "5000/5000 [==============================] - 1272s 254ms/step - loss: 0.0136 - val_loss: 0.0120\n",
      "\n",
      "Epoch 00043: saving model to model-43.h5\n",
      "Epoch 44/200\n",
      "5000/5000 [==============================] - 1273s 255ms/step - loss: 0.0135 - val_loss: 0.0123\n",
      "\n",
      "Epoch 00044: saving model to model-44.h5\n",
      "Epoch 45/200\n",
      "5000/5000 [==============================] - 1278s 256ms/step - loss: 0.0132 - val_loss: 0.0126\n",
      "\n",
      "Epoch 00045: saving model to model-45.h5\n",
      "Epoch 46/200\n",
      "5000/5000 [==============================] - 1278s 256ms/step - loss: 0.0133 - val_loss: 0.0128\n",
      "\n",
      "Epoch 00046: saving model to model-46.h5\n",
      "Epoch 47/200\n",
      "5000/5000 [==============================] - 1279s 256ms/step - loss: 0.0132 - val_loss: 0.0123\n",
      "\n",
      "Epoch 00047: saving model to model-47.h5\n",
      "Epoch 48/200\n",
      "5000/5000 [==============================] - 1275s 255ms/step - loss: 0.0132 - val_loss: 0.0122\n",
      "\n",
      "Epoch 00048: saving model to model-48.h5\n",
      "Epoch 49/200\n",
      "5000/5000 [==============================] - 1274s 255ms/step - loss: 0.0132 - val_loss: 0.0123\n",
      "\n",
      "Epoch 00049: saving model to model-49.h5\n",
      "Epoch 50/200\n",
      "5000/5000 [==============================] - 1277s 255ms/step - loss: 0.0130 - val_loss: 0.0125\n",
      "\n",
      "Epoch 00050: saving model to model-50.h5\n",
      "Epoch 51/200\n",
      "5000/5000 [==============================] - 1275s 255ms/step - loss: 0.0131 - val_loss: 0.0122\n",
      "\n",
      "Epoch 00051: saving model to model-51.h5\n",
      "Epoch 52/200\n",
      "5000/5000 [==============================] - 1279s 256ms/step - loss: 0.0130 - val_loss: 0.0118\n",
      "\n",
      "Epoch 00052: saving model to model-52.h5\n",
      "Epoch 53/200\n",
      "5000/5000 [==============================] - 1277s 255ms/step - loss: 0.0128 - val_loss: 0.0119\n",
      "\n",
      "Epoch 00053: saving model to model-53.h5\n",
      "Epoch 54/200\n",
      "5000/5000 [==============================] - 1278s 256ms/step - loss: 0.0127 - val_loss: 0.0123\n",
      "\n",
      "Epoch 00054: saving model to model-54.h5\n",
      "Epoch 55/200\n",
      "5000/5000 [==============================] - 1281s 256ms/step - loss: 0.0128 - val_loss: 0.0123\n",
      "\n",
      "Epoch 00055: saving model to model-55.h5\n",
      "Epoch 56/200\n",
      "5000/5000 [==============================] - 1278s 256ms/step - loss: 0.0128 - val_loss: 0.0117\n",
      "\n",
      "Epoch 00056: saving model to model-56.h5\n",
      "Epoch 57/200\n",
      "5000/5000 [==============================] - 1273s 255ms/step - loss: 0.0130 - val_loss: 0.0121\n",
      "\n",
      "Epoch 00057: saving model to model-57.h5\n",
      "Epoch 58/200\n",
      "5000/5000 [==============================] - 1275s 255ms/step - loss: 0.0128 - val_loss: 0.0117\n",
      "\n",
      "Epoch 00058: saving model to model-58.h5\n",
      "Epoch 59/200\n",
      "5000/5000 [==============================] - 1277s 255ms/step - loss: 0.0127 - val_loss: 0.0120\n",
      "\n",
      "Epoch 00059: saving model to model-59.h5\n",
      "Epoch 60/200\n",
      "5000/5000 [==============================] - 1277s 255ms/step - loss: 0.0128 - val_loss: 0.0121\n",
      "\n",
      "Epoch 00060: saving model to model-60.h5\n",
      "Epoch 61/200\n",
      "5000/5000 [==============================] - 1278s 256ms/step - loss: 0.0124 - val_loss: 0.0118\n",
      "\n",
      "Epoch 00061: saving model to model-61.h5\n",
      "Epoch 62/200\n",
      "5000/5000 [==============================] - 1296s 259ms/step - loss: 0.0127 - val_loss: 0.0117\n",
      "\n",
      "Epoch 00062: saving model to model-62.h5\n",
      "Epoch 63/200\n",
      "5000/5000 [==============================] - 1282s 256ms/step - loss: 0.0125 - val_loss: 0.0116\n",
      "\n",
      "Epoch 00063: saving model to model-63.h5\n",
      "Epoch 64/200\n",
      "5000/5000 [==============================] - 26392s 5s/step - loss: 0.0121 - val_loss: 0.0115\n",
      "\n",
      "Epoch 00064: saving model to model-64.h5\n",
      "Epoch 65/200\n",
      "5000/5000 [==============================] - 1961s 392ms/step - loss: 0.0117 - val_loss: 0.0117\n",
      "\n",
      "Epoch 00065: saving model to model-65.h5\n",
      "Epoch 66/200\n",
      "5000/5000 [==============================] - 1317s 263ms/step - loss: 0.0119 - val_loss: 0.0117\n",
      "\n",
      "Epoch 00066: saving model to model-66.h5\n",
      "Epoch 67/200\n",
      "5000/5000 [==============================] - 1348s 270ms/step - loss: 0.0117 - val_loss: 0.0114\n",
      "\n",
      "Epoch 00067: saving model to model-67.h5\n",
      "Epoch 68/200\n",
      "5000/5000 [==============================] - 1380s 276ms/step - loss: 0.0115 - val_loss: 0.0116\n",
      "\n",
      "Epoch 00068: saving model to model-68.h5\n",
      "Epoch 69/200\n",
      "5000/5000 [==============================] - 1492s 298ms/step - loss: 0.0110 - val_loss: 0.0114\n",
      "\n",
      "Epoch 00069: saving model to model-69.h5\n",
      "Epoch 70/200\n",
      "5000/5000 [==============================] - 1329s 266ms/step - loss: 0.0114 - val_loss: 0.0117\n",
      "\n",
      "Epoch 00070: saving model to model-70.h5\n",
      "Epoch 71/200\n",
      "5000/5000 [==============================] - 1411s 282ms/step - loss: 0.0113 - val_loss: 0.0110\n",
      "\n",
      "Epoch 00071: saving model to model-71.h5\n",
      "Epoch 72/200\n",
      "5000/5000 [==============================] - 1558s 312ms/step - loss: 0.0109 - val_loss: 0.0116\n",
      "\n",
      "Epoch 00072: saving model to model-72.h5\n",
      "Epoch 73/200\n",
      "5000/5000 [==============================] - 1565s 313ms/step - loss: 0.0109 - val_loss: 0.0111\n",
      "\n",
      "Epoch 00073: saving model to model-73.h5\n",
      "Epoch 74/200\n",
      "5000/5000 [==============================] - 1445s 289ms/step - loss: 0.0112 - val_loss: 0.0113\n",
      "\n",
      "Epoch 00074: saving model to model-74.h5\n",
      "Epoch 75/200\n",
      "5000/5000 [==============================] - 1423s 285ms/step - loss: 0.0111 - val_loss: 0.0115\n",
      "\n",
      "Epoch 00075: saving model to model-75.h5\n",
      "Epoch 76/200\n",
      "5000/5000 [==============================] - 1434s 287ms/step - loss: 0.0112 - val_loss: 0.0110\n",
      "\n",
      "Epoch 00076: saving model to model-76.h5\n",
      "Epoch 77/200\n",
      "5000/5000 [==============================] - 1440s 288ms/step - loss: 0.0110 - val_loss: 0.0113\n",
      "\n",
      "Epoch 00077: saving model to model-77.h5\n",
      "Epoch 78/200\n",
      "5000/5000 [==============================] - 1441s 288ms/step - loss: 0.0110 - val_loss: 0.0114\n",
      "\n",
      "Epoch 00078: saving model to model-78.h5\n",
      "Epoch 79/200\n",
      "5000/5000 [==============================] - 1551s 310ms/step - loss: 0.0109 - val_loss: 0.0108\n",
      "\n",
      "Epoch 00079: saving model to model-79.h5\n",
      "Epoch 80/200\n",
      "5000/5000 [==============================] - 1458s 292ms/step - loss: 0.0108 - val_loss: 0.0112\n",
      "\n",
      "Epoch 00080: saving model to model-80.h5\n",
      "Epoch 81/200\n",
      "5000/5000 [==============================] - 1462s 292ms/step - loss: 0.0109 - val_loss: 0.0113\n",
      "\n",
      "Epoch 00081: saving model to model-81.h5\n",
      "Epoch 82/200\n",
      "5000/5000 [==============================] - 1380s 276ms/step - loss: 0.0108 - val_loss: 0.0111\n",
      "\n",
      "Epoch 00082: saving model to model-82.h5\n",
      "Epoch 83/200\n",
      "5000/5000 [==============================] - 1389s 278ms/step - loss: 0.0110 - val_loss: 0.0111\n",
      "\n",
      "Epoch 00083: saving model to model-83.h5\n",
      "Epoch 84/200\n",
      "5000/5000 [==============================] - 1387s 277ms/step - loss: 0.0109 - val_loss: 0.0110\n",
      "\n",
      "Epoch 00084: saving model to model-84.h5\n",
      "Epoch 85/200\n",
      "5000/5000 [==============================] - 1435s 287ms/step - loss: 0.0110 - val_loss: 0.0112\n",
      "\n",
      "Epoch 00085: saving model to model-85.h5\n",
      "Epoch 86/200\n",
      "5000/5000 [==============================] - 1274s 255ms/step - loss: 0.0115 - val_loss: 0.0113\n",
      "\n",
      "Epoch 00086: saving model to model-86.h5\n",
      "Epoch 87/200\n",
      "5000/5000 [==============================] - 1259s 252ms/step - loss: 0.0119 - val_loss: 0.0112\n",
      "\n",
      "Epoch 00087: saving model to model-87.h5\n",
      "Epoch 88/200\n",
      "5000/5000 [==============================] - 1267s 253ms/step - loss: 0.0117 - val_loss: 0.0114\n",
      "\n",
      "Epoch 00088: saving model to model-88.h5\n",
      "Epoch 89/200\n",
      "5000/5000 [==============================] - 1263s 253ms/step - loss: 0.0118 - val_loss: 0.0110\n",
      "\n",
      "Epoch 00089: saving model to model-89.h5\n",
      "Epoch 90/200\n",
      "5000/5000 [==============================] - 1258s 252ms/step - loss: 0.0119 - val_loss: 0.0111\n",
      "\n",
      "Epoch 00090: saving model to model-90.h5\n",
      "Epoch 91/200\n",
      "5000/5000 [==============================] - 1258s 252ms/step - loss: 0.0118 - val_loss: 0.0110\n",
      "\n",
      "Epoch 00091: saving model to model-91.h5\n",
      "Epoch 92/200\n",
      "5000/5000 [==============================] - 1257s 251ms/step - loss: 0.0119 - val_loss: 0.0110\n",
      "\n",
      "Epoch 00092: saving model to model-92.h5\n",
      "Epoch 93/200\n",
      "5000/5000 [==============================] - 1258s 252ms/step - loss: 0.0117 - val_loss: 0.0111\n",
      "\n",
      "Epoch 00093: saving model to model-93.h5\n",
      "Epoch 94/200\n",
      "5000/5000 [==============================] - 1258s 252ms/step - loss: 0.0116 - val_loss: 0.0111\n",
      "\n",
      "Epoch 00094: saving model to model-94.h5\n",
      "Epoch 95/200\n",
      "5000/5000 [==============================] - 1259s 252ms/step - loss: 0.0116 - val_loss: 0.0111\n",
      "\n",
      "Epoch 00095: saving model to model-95.h5\n",
      "Epoch 96/200\n",
      "5000/5000 [==============================] - 1259s 252ms/step - loss: 0.0119 - val_loss: 0.0110\n",
      "\n",
      "Epoch 00096: saving model to model-96.h5\n",
      "Epoch 97/200\n",
      "5000/5000 [==============================] - 1266s 253ms/step - loss: 0.0116 - val_loss: 0.0111\n",
      "\n",
      "Epoch 00097: saving model to model-97.h5\n",
      "Epoch 98/200\n",
      "5000/5000 [==============================] - 1261s 252ms/step - loss: 0.0117 - val_loss: 0.0109\n",
      "\n",
      "Epoch 00098: saving model to model-98.h5\n",
      "Epoch 99/200\n",
      "5000/5000 [==============================] - 1261s 252ms/step - loss: 0.0115 - val_loss: 0.0114\n",
      "\n",
      "Epoch 00099: saving model to model-99.h5\n",
      "Epoch 100/200\n",
      "5000/5000 [==============================] - 1264s 253ms/step - loss: 0.0114 - val_loss: 0.0112\n",
      "\n",
      "Epoch 00100: saving model to model-100.h5\n",
      "Epoch 101/200\n",
      "5000/5000 [==============================] - 1259s 252ms/step - loss: 0.0115 - val_loss: 0.0111\n",
      "\n",
      "Epoch 00101: saving model to model-101.h5\n",
      "Epoch 102/200\n",
      "5000/5000 [==============================] - 1263s 253ms/step - loss: 0.0116 - val_loss: 0.0111\n",
      "\n",
      "Epoch 00102: saving model to model-102.h5\n",
      "Epoch 103/200\n",
      "5000/5000 [==============================] - 1264s 253ms/step - loss: 0.0116 - val_loss: 0.0110\n",
      "\n",
      "Epoch 00103: saving model to model-103.h5\n",
      "Epoch 104/200\n",
      "5000/5000 [==============================] - 1261s 252ms/step - loss: 0.0115 - val_loss: 0.0113\n",
      "\n",
      "Epoch 00104: saving model to model-104.h5\n",
      "Epoch 105/200\n",
      "5000/5000 [==============================] - 1213s 243ms/step - loss: 0.0113 - val_loss: 0.0127\n",
      "\n",
      "Epoch 00105: saving model to model-105.h5\n",
      "Epoch 106/200\n",
      "5000/5000 [==============================] - 1224s 245ms/step - loss: 0.0112 - val_loss: 0.0116\n",
      "\n",
      "Epoch 00106: saving model to model-106.h5\n",
      "Epoch 107/200\n",
      "5000/5000 [==============================] - 1207s 241ms/step - loss: 0.0112 - val_loss: 0.0122\n",
      "\n",
      "Epoch 00107: saving model to model-107.h5\n",
      "Epoch 108/200\n",
      "5000/5000 [==============================] - 1208s 242ms/step - loss: 0.0115 - val_loss: 0.0130\n",
      "\n",
      "Epoch 00108: saving model to model-108.h5\n",
      "Epoch 109/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000/5000 [==============================] - 1207s 241ms/step - loss: 0.0113 - val_loss: 0.0124\n",
      "\n",
      "Epoch 00109: saving model to model-109.h5\n",
      "Epoch 110/200\n",
      "5000/5000 [==============================] - 1209s 242ms/step - loss: 0.0116 - val_loss: 0.0123\n",
      "\n",
      "Epoch 00110: saving model to model-110.h5\n",
      "Epoch 111/200\n",
      "5000/5000 [==============================] - 1214s 243ms/step - loss: 0.0117 - val_loss: 0.0124\n",
      "\n",
      "Epoch 00111: saving model to model-111.h5\n",
      "Epoch 112/200\n",
      "5000/5000 [==============================] - 1208s 242ms/step - loss: 0.0112 - val_loss: 0.0125\n",
      "\n",
      "Epoch 00112: saving model to model-112.h5\n",
      "Epoch 113/200\n",
      "5000/5000 [==============================] - 1208s 242ms/step - loss: 0.0111 - val_loss: 0.0126\n",
      "\n",
      "Epoch 00113: saving model to model-113.h5\n",
      "Epoch 114/200\n",
      "5000/5000 [==============================] - 1275s 255ms/step - loss: 0.0110 - val_loss: 0.0104\n",
      "\n",
      "Epoch 00114: saving model to model-114.h5\n",
      "Epoch 115/200\n",
      "5000/5000 [==============================] - 1278s 256ms/step - loss: 0.0112 - val_loss: 0.0111\n",
      "\n",
      "Epoch 00115: saving model to model-115.h5\n",
      "Epoch 116/200\n",
      "5000/5000 [==============================] - 1252s 250ms/step - loss: 0.0114 - val_loss: 0.0112\n",
      "\n",
      "Epoch 00116: saving model to model-116.h5\n",
      "Epoch 117/200\n",
      "5000/5000 [==============================] - 1371s 274ms/step - loss: 0.0111 - val_loss: 0.0106\n",
      "\n",
      "Epoch 00117: saving model to model-117.h5\n",
      "Epoch 118/200\n",
      "5000/5000 [==============================] - 1984s 397ms/step - loss: 0.0094 - val_loss: 0.0099\n",
      "\n",
      "Epoch 00118: saving model to model-118.h5\n",
      "Epoch 119/200\n",
      "5000/5000 [==============================] - 1464s 293ms/step - loss: 0.0096 - val_loss: 0.0105\n",
      "\n",
      "Epoch 00119: saving model to model-119.h5\n",
      "Epoch 120/200\n",
      "5000/5000 [==============================] - 1342s 268ms/step - loss: 0.0101 - val_loss: 0.0104\n",
      "\n",
      "Epoch 00120: saving model to model-120.h5\n",
      "Epoch 121/200\n",
      "5000/5000 [==============================] - 1356s 271ms/step - loss: 0.0101 - val_loss: 0.0108\n",
      "\n",
      "Epoch 00121: saving model to model-121.h5\n",
      "Epoch 122/200\n",
      "5000/5000 [==============================] - 1343s 269ms/step - loss: 0.0102 - val_loss: 0.0104\n",
      "\n",
      "Epoch 00122: saving model to model-122.h5\n",
      "Epoch 123/200\n",
      "5000/5000 [==============================] - 1335s 267ms/step - loss: 0.0103 - val_loss: 0.0107\n",
      "\n",
      "Epoch 00123: saving model to model-123.h5\n",
      "Epoch 124/200\n",
      "5000/5000 [==============================] - 1332s 266ms/step - loss: 0.0108 - val_loss: 0.0104\n",
      "\n",
      "Epoch 00124: saving model to model-124.h5\n",
      "Epoch 125/200\n",
      "5000/5000 [==============================] - 1345s 269ms/step - loss: 0.0104 - val_loss: 0.0105\n",
      "\n",
      "Epoch 00125: saving model to model-125.h5\n",
      "Epoch 126/200\n",
      "5000/5000 [==============================] - 1400s 280ms/step - loss: 0.0104 - val_loss: 0.0104\n",
      "\n",
      "Epoch 00126: saving model to model-126.h5\n",
      "Epoch 127/200\n",
      "5000/5000 [==============================] - 1574s 315ms/step - loss: 0.0100 - val_loss: 0.0104\n",
      "\n",
      "Epoch 00127: saving model to model-127.h5\n",
      "Epoch 128/200\n",
      "5000/5000 [==============================] - 1280s 256ms/step - loss: 0.0108 - val_loss: 0.0108\n",
      "\n",
      "Epoch 00128: saving model to model-128.h5\n",
      "Epoch 129/200\n",
      "5000/5000 [==============================] - 1265s 253ms/step - loss: 0.0113 - val_loss: 0.0108\n",
      "\n",
      "Epoch 00129: saving model to model-129.h5\n",
      "Epoch 130/200\n",
      "5000/5000 [==============================] - 1290s 258ms/step - loss: 0.0108 - val_loss: 0.0107\n",
      "\n",
      "Epoch 00130: saving model to model-130.h5\n",
      "Epoch 131/200\n",
      "5000/5000 [==============================] - 1267s 253ms/step - loss: 0.0110 - val_loss: 0.0105\n",
      "\n",
      "Epoch 00131: saving model to model-131.h5\n",
      "Epoch 132/200\n",
      "5000/5000 [==============================] - 1261s 252ms/step - loss: 0.0112 - val_loss: 0.0106\n",
      "\n",
      "Epoch 00132: saving model to model-132.h5\n",
      "Epoch 133/200\n",
      "5000/5000 [==============================] - 1265s 253ms/step - loss: 0.0111 - val_loss: 0.0105\n",
      "\n",
      "Epoch 00133: saving model to model-133.h5\n",
      "Epoch 134/200\n",
      "5000/5000 [==============================] - 1265s 253ms/step - loss: 0.0111 - val_loss: 0.0103\n",
      "\n",
      "Epoch 00134: saving model to model-134.h5\n",
      "Epoch 135/200\n",
      "5000/5000 [==============================] - 1264s 253ms/step - loss: 0.0110 - val_loss: 0.0109\n",
      "\n",
      "Epoch 00135: saving model to model-135.h5\n",
      "Epoch 136/200\n",
      "5000/5000 [==============================] - 1275s 255ms/step - loss: 0.0112 - val_loss: 0.0105\n",
      "\n",
      "Epoch 00136: saving model to model-136.h5\n",
      "Epoch 137/200\n",
      "5000/5000 [==============================] - 1266s 253ms/step - loss: 0.0109 - val_loss: 0.0108\n",
      "\n",
      "Epoch 00137: saving model to model-137.h5\n",
      "Epoch 138/200\n",
      "5000/5000 [==============================] - 1136s 227ms/step - loss: 0.0107 - val_loss: 0.0139\n",
      "\n",
      "Epoch 00138: saving model to model-138.h5\n",
      "Epoch 139/200\n",
      "5000/5000 [==============================] - 1180s 236ms/step - loss: 0.0107 - val_loss: 0.0130\n",
      "\n",
      "Epoch 00139: saving model to model-139.h5\n",
      "Epoch 140/200\n",
      "5000/5000 [==============================] - 1689s 338ms/step - loss: 0.0089 - val_loss: 0.0124\n",
      "\n",
      "Epoch 00140: saving model to model-140.h5\n",
      "Epoch 141/200\n",
      "5000/5000 [==============================] - 1294s 259ms/step - loss: 0.0096 - val_loss: 0.0129\n",
      "\n",
      "Epoch 00141: saving model to model-141.h5\n",
      "Epoch 142/200\n",
      "5000/5000 [==============================] - 1357s 271ms/step - loss: 0.0097 - val_loss: 0.0128\n",
      "\n",
      "Epoch 00142: saving model to model-142.h5\n",
      "Epoch 143/200\n",
      "5000/5000 [==============================] - 1224s 245ms/step - loss: 0.0103 - val_loss: 0.0138\n",
      "\n",
      "Epoch 00143: saving model to model-143.h5\n",
      "Epoch 144/200\n",
      "5000/5000 [==============================] - 1192s 238ms/step - loss: 0.0106 - val_loss: 0.0139\n",
      "\n",
      "Epoch 00144: saving model to model-144.h5\n",
      "Epoch 145/200\n",
      "5000/5000 [==============================] - 1177s 235ms/step - loss: 0.0108 - val_loss: 0.0135\n",
      "\n",
      "Epoch 00145: saving model to model-145.h5\n",
      "Epoch 146/200\n",
      "5000/5000 [==============================] - 2372s 474ms/step - loss: 0.0104 - val_loss: 0.0123\n",
      "\n",
      "Epoch 00146: saving model to model-146.h5\n",
      "Epoch 147/200\n",
      "5000/5000 [==============================] - 1292s 258ms/step - loss: 0.0099 - val_loss: 0.0134\n",
      "\n",
      "Epoch 00147: saving model to model-147.h5\n",
      "Epoch 148/200\n",
      "5000/5000 [==============================] - 1117s 223ms/step - loss: 0.0108 - val_loss: 0.0143\n",
      "\n",
      "Epoch 00148: saving model to model-148.h5\n",
      "Epoch 149/200\n",
      "5000/5000 [==============================] - 1107s 221ms/step - loss: 0.0112 - val_loss: 0.0136\n",
      "\n",
      "Epoch 00149: saving model to model-149.h5\n",
      "Epoch 150/200\n",
      "5000/5000 [==============================] - 1101s 220ms/step - loss: 0.0110 - val_loss: 0.0142\n",
      "\n",
      "Epoch 00150: saving model to model-150.h5\n",
      "Epoch 151/200\n",
      "5000/5000 [==============================] - 1101s 220ms/step - loss: 0.0108 - val_loss: 0.0138\n",
      "\n",
      "Epoch 00151: saving model to model-151.h5\n",
      "Epoch 152/200\n",
      "5000/5000 [==============================] - 1101s 220ms/step - loss: 0.0111 - val_loss: 0.0143\n",
      "\n",
      "Epoch 00152: saving model to model-152.h5\n",
      "Epoch 153/200\n",
      "5000/5000 [==============================] - 1102s 220ms/step - loss: 0.0108 - val_loss: 0.0141\n",
      "\n",
      "Epoch 00153: saving model to model-153.h5\n",
      "Epoch 154/200\n",
      "5000/5000 [==============================] - 1106s 221ms/step - loss: 0.0112 - val_loss: 0.0136\n",
      "\n",
      "Epoch 00154: saving model to model-154.h5\n",
      "Epoch 155/200\n",
      "5000/5000 [==============================] - 1099s 220ms/step - loss: 0.0110 - val_loss: 0.0141\n",
      "\n",
      "Epoch 00155: saving model to model-155.h5\n",
      "Epoch 156/200\n",
      "5000/5000 [==============================] - 1098s 220ms/step - loss: 0.0110 - val_loss: 0.0140\n",
      "\n",
      "Epoch 00156: saving model to model-156.h5\n",
      "Epoch 157/200\n",
      "5000/5000 [==============================] - 1095s 219ms/step - loss: 0.0110 - val_loss: 0.0142\n",
      "\n",
      "Epoch 00157: saving model to model-157.h5\n",
      "Epoch 158/200\n",
      "5000/5000 [==============================] - 1093s 219ms/step - loss: 0.0109 - val_loss: 0.0141\n",
      "\n",
      "Epoch 00158: saving model to model-158.h5\n",
      "Epoch 159/200\n",
      "5000/5000 [==============================] - 1094s 219ms/step - loss: 0.0111 - val_loss: 0.0135\n",
      "\n",
      "Epoch 00159: saving model to model-159.h5\n",
      "Epoch 160/200\n",
      "5000/5000 [==============================] - 1094s 219ms/step - loss: 0.0110 - val_loss: 0.0140\n",
      "\n",
      "Epoch 00160: saving model to model-160.h5\n",
      "Epoch 161/200\n",
      "5000/5000 [==============================] - 1089s 218ms/step - loss: 0.0110 - val_loss: 0.0143\n",
      "\n",
      "Epoch 00161: saving model to model-161.h5\n",
      "Epoch 162/200\n",
      "5000/5000 [==============================] - 1093s 219ms/step - loss: 0.0112 - val_loss: 0.0138\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00162: saving model to model-162.h5\n",
      "Epoch 163/200\n",
      "5000/5000 [==============================] - 1096s 219ms/step - loss: 0.0112 - val_loss: 0.0136\n",
      "\n",
      "Epoch 00163: saving model to model-163.h5\n",
      "Epoch 164/200\n",
      "5000/5000 [==============================] - 1097s 219ms/step - loss: 0.0112 - val_loss: 0.0138\n",
      "\n",
      "Epoch 00164: saving model to model-164.h5\n",
      "Epoch 165/200\n",
      "5000/5000 [==============================] - 1095s 219ms/step - loss: 0.0109 - val_loss: 0.0140\n",
      "\n",
      "Epoch 00165: saving model to model-165.h5\n",
      "Epoch 166/200\n",
      "5000/5000 [==============================] - 1094s 219ms/step - loss: 0.0111 - val_loss: 0.0142\n",
      "\n",
      "Epoch 00166: saving model to model-166.h5\n",
      "Epoch 167/200\n",
      "5000/5000 [==============================] - 1094s 219ms/step - loss: 0.0112 - val_loss: 0.0138\n",
      "\n",
      "Epoch 00167: saving model to model-167.h5\n",
      "Epoch 168/200\n",
      "5000/5000 [==============================] - 1094s 219ms/step - loss: 0.0109 - val_loss: 0.0137\n",
      "\n",
      "Epoch 00168: saving model to model-168.h5\n",
      "Epoch 169/200\n",
      "5000/5000 [==============================] - 1099s 220ms/step - loss: 0.0113 - val_loss: 0.0137\n",
      "\n",
      "Epoch 00169: saving model to model-169.h5\n",
      "Epoch 170/200\n",
      "5000/5000 [==============================] - 1094s 219ms/step - loss: 0.0109 - val_loss: 0.0138\n",
      "\n",
      "Epoch 00170: saving model to model-170.h5\n",
      "Epoch 171/200\n",
      "5000/5000 [==============================] - 1093s 219ms/step - loss: 0.0112 - val_loss: 0.0143\n",
      "\n",
      "Epoch 00171: saving model to model-171.h5\n",
      "Epoch 172/200\n",
      "5000/5000 [==============================] - 1095s 219ms/step - loss: 0.0110 - val_loss: 0.0137\n",
      "\n",
      "Epoch 00172: saving model to model-172.h5\n",
      "Epoch 173/200\n",
      "5000/5000 [==============================] - 1095s 219ms/step - loss: 0.0112 - val_loss: 0.0138\n",
      "\n",
      "Epoch 00173: saving model to model-173.h5\n",
      "Epoch 174/200\n",
      "5000/5000 [==============================] - 8637s 2s/step - loss: 0.0112 - val_loss: 0.0140\n",
      "\n",
      "Epoch 00174: saving model to model-174.h5\n",
      "Epoch 175/200\n",
      "5000/5000 [==============================] - 4757s 951ms/step - loss: 0.0098 - val_loss: 0.0132\n",
      "\n",
      "Epoch 00175: saving model to model-175.h5\n",
      "Epoch 176/200\n",
      "5000/5000 [==============================] - 1225s 245ms/step - loss: 0.0097 - val_loss: 0.0130\n",
      "\n",
      "Epoch 00176: saving model to model-176.h5\n",
      "Epoch 177/200\n",
      "5000/5000 [==============================] - 1269s 254ms/step - loss: 0.0107 - val_loss: 0.0130\n",
      "\n",
      "Epoch 00177: saving model to model-177.h5\n",
      "Epoch 178/200\n",
      "5000/5000 [==============================] - 1140s 228ms/step - loss: 0.0109 - val_loss: 0.0132\n",
      "\n",
      "Epoch 00178: saving model to model-178.h5\n",
      "Epoch 179/200\n",
      "5000/5000 [==============================] - 1174s 235ms/step - loss: 0.0102 - val_loss: 0.0129\n",
      "\n",
      "Epoch 00179: saving model to model-179.h5\n",
      "Epoch 180/200\n",
      "5000/5000 [==============================] - 1171s 234ms/step - loss: 0.0104 - val_loss: 0.0135\n",
      "\n",
      "Epoch 00180: saving model to model-180.h5\n",
      "Epoch 181/200\n",
      "5000/5000 [==============================] - 1303s 261ms/step - loss: 0.0104 - val_loss: 0.0101\n",
      "\n",
      "Epoch 00181: saving model to model-181.h5\n",
      "Epoch 182/200\n",
      "5000/5000 [==============================] - 1346s 269ms/step - loss: 0.0098 - val_loss: 0.0102\n",
      "\n",
      "Epoch 00182: saving model to model-182.h5\n",
      "Epoch 183/200\n",
      "5000/5000 [==============================] - 1298s 260ms/step - loss: 0.0100 - val_loss: 0.0101\n",
      "\n",
      "Epoch 00183: saving model to model-183.h5\n",
      "Epoch 184/200\n",
      "5000/5000 [==============================] - 1300s 260ms/step - loss: 0.0104 - val_loss: 0.0102\n",
      "\n",
      "Epoch 00184: saving model to model-184.h5\n",
      "Epoch 185/200\n",
      "5000/5000 [==============================] - 1323s 265ms/step - loss: 0.0104 - val_loss: 0.0102\n",
      "\n",
      "Epoch 00185: saving model to model-185.h5\n",
      "Epoch 186/200\n",
      "5000/5000 [==============================] - 1300s 260ms/step - loss: 0.0102 - val_loss: 0.0102\n",
      "\n",
      "Epoch 00186: saving model to model-186.h5\n",
      "Epoch 187/200\n",
      "5000/5000 [==============================] - 5091s 1s/step - loss: 0.0103 - val_loss: 0.0109\n",
      "\n",
      "Epoch 00187: saving model to model-187.h5\n",
      "Epoch 188/200\n",
      "5000/5000 [==============================] - 1887s 377ms/step - loss: 0.0099 - val_loss: 0.0138\n",
      "\n",
      "Epoch 00188: saving model to model-188.h5\n",
      "Epoch 189/200\n",
      "5000/5000 [==============================] - 1147s 229ms/step - loss: 0.0099 - val_loss: 0.0140\n",
      "\n",
      "Epoch 00189: saving model to model-189.h5\n",
      "Epoch 190/200\n",
      "5000/5000 [==============================] - 1146s 229ms/step - loss: 0.0100 - val_loss: 0.0135\n",
      "\n",
      "Epoch 00190: saving model to model-190.h5\n",
      "Epoch 191/200\n",
      "5000/5000 [==============================] - 1158s 232ms/step - loss: 0.0096 - val_loss: 0.0136\n",
      "\n",
      "Epoch 00191: saving model to model-191.h5\n",
      "Epoch 192/200\n",
      "5000/5000 [==============================] - 1445s 289ms/step - loss: 0.0091 - val_loss: 0.0138\n",
      "\n",
      "Epoch 00192: saving model to model-192.h5\n",
      "Epoch 193/200\n",
      "5000/5000 [==============================] - 1173s 235ms/step - loss: 0.0098 - val_loss: 0.0134\n",
      "\n",
      "Epoch 00193: saving model to model-193.h5\n",
      "Epoch 194/200\n",
      "5000/5000 [==============================] - 1267s 253ms/step - loss: 0.0091 - val_loss: 0.0134\n",
      "\n",
      "Epoch 00194: saving model to model-194.h5\n",
      "Epoch 195/200\n",
      "5000/5000 [==============================] - 1240s 248ms/step - loss: 0.0093 - val_loss: 0.0132\n",
      "\n",
      "Epoch 00195: saving model to model-195.h5\n",
      "Epoch 196/200\n",
      "5000/5000 [==============================] - 1386s 277ms/step - loss: 0.0092 - val_loss: 0.0100\n",
      "\n",
      "Epoch 00196: saving model to model-196.h5\n",
      "Epoch 197/200\n",
      "5000/5000 [==============================] - 1348s 270ms/step - loss: 0.0095 - val_loss: 0.0100\n",
      "\n",
      "Epoch 00197: saving model to model-197.h5\n",
      "Epoch 198/200\n",
      "5000/5000 [==============================] - 1334s 267ms/step - loss: 0.0099 - val_loss: 0.0103\n",
      "\n",
      "Epoch 00198: saving model to model-198.h5\n",
      "Epoch 199/200\n",
      "5000/5000 [==============================] - 1298s 260ms/step - loss: 0.0104 - val_loss: 0.0103\n",
      "\n",
      "Epoch 00199: saving model to model-199.h5\n",
      "Epoch 200/200\n",
      "5000/5000 [==============================] - 1306s 261ms/step - loss: 0.0098 - val_loss: 0.0100\n",
      "\n",
      "Epoch 00200: saving model to model-200.h5\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
